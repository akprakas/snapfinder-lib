#!/bin/sh

# mongo host ip
IP=${IP:=127.0.0.1}

alias mongo="mongo --host $IP"
alias mongoimport="mongoimport --host $IP"

logdb()
{
  timestamp=`date`
  mongo snapdb --eval "db.harvestlog.insert({timestamp:\"$timestamp\", category:\"$1\", message:\"$2\"})"
}

log()
{
  echo $1
  echo "`date +"%b %d %T"` $1" >> import.log
  logdb info $1
}

logerror()
{
  echo $1
  echo "`date +"%b %d %T"` $1" >> error.log
  logdb error $1 
}  

error_exit()
{
  log "error: $2 (check error.log)"
  exit ${1:-1}
}

log started

# currently not necessary since writing to local mongo
#[ -n "$APIUSER" ] || error_exit 1 "APIUSER environment variable not set"
#[ -n "$APIPASS" ] || error_exit 1 "APIPASS environment variable not set"
#[ -n "$APIHOST" ] || error_exit 1 "APIHOST environment variable not set"

log "downloading snap data"
curl -O --fail --silent --show-error  www.snapretailerlocator.com/export/Nationwide.zip 2>> error.log || error_exit 1 "curl failed"

log "extracting data"
unzip -o Nationwide.zip 2>> error.log || error_exit 1 "unzip failed" 
csv=`ls store_locations*.csv`

# slice off header row or mongo will either use those names instead of
# the provided ones or else will insert as a documenting, depending on
# presence of --headerline
# tail =n +2 "$csv"

log "importing data to mongo"
FIELDS="storeName,longitude,latitude,address1,address2,city,state,zip5,zip4,county"
#mongoimport -u $APIUSER -p $APIPASS --host $APIHOST --db snapdb --collection stores --fields $FIELDS --type csv --drop < $csv 2>> error.log || error_exit 1 "mongo import failed"

mongoimport --db snapdb --collection stores --fields $FIELDS --type csv --drop < $csv 2>> error.log || error_exit 1 "mongo import failed"

mongo snapdb postimport.js

log finished

# always cleanup
trap "rm -f *.zip *.csv" EXIT
